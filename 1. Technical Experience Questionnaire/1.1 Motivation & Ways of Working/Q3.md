# 1.3 How do you usually collaborate with product managers, platform engineers, or data/research teams to deliver AI solutions?

---

**Product Managers**

Mainly liaising about the requirements, acceptance criteria, project timeline, user story, story points (if using agile methodology), user flow, expected behaviour or complex behaviour, UI thought process (if UI design is required by dev)

If faced with any question or concern, rediscuss with product managers about the question or concern and come to a consensus. If the question or concern is tech related, provide suggestions to them as well, so they can make a more confident and suitable decision.

**Platform Engineer**

(never worked with a platform engineer, so this is my assumption based on the job scope of platform engineer i can find online.)

Will be working together and convert product requirements into clear technical boundaries that guide infrastructure decisions. Having discussion to define acceptable failure rates, response-time budgets, and other operational metrics, and clarify which logic belongs in the model stack versus the application layer.

Before any development, will be aligning with platform engineers on API structures, data formats, model outputs, versioning rules, and fine-tuning workflows. If error occurs, I will try to do my own discovery first, if the issue cannot be identified, then will be having joint debugging with them to resolve the issue.

After deployment, will be working along to monitor system health, adjust scaling behavior, maintain security constraints, and update pipelines as the model and requirements evolve.

**Data/Research team**

(I have never worked with a data/research team either, so this is my assumption based on the job scope of data/research team i can find online.)

Will be working on defining the target behaviors, data boundaries, evaluation standards, and model constraints that translate product goals into concrete research direction. Will discuss with them on what specific data the model must infer and what must be imposed through rules to prevent misalignment.

Will be working with them to define what each feature means, review their experiment results to understand where the model struggles, and discuss how to handle edge cases. When there's confusion about model outputs, will align on the interpretation so everyone is on the same page about what different results mean in different situations.

After deployment, will be monitoring how the model performs with real-world data, regularly checking with them on data quality issues, and updating the evaluation process when needed. When they release new model versions, will coordinate to make sure the changes don't break existing integrations or affect what we've promised to users.
