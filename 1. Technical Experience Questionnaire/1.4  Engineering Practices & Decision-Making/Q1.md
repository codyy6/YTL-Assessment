# 1.4.1 How have you applied modern engineering practices (CI/CD, observability, testing, cloud-native deployment) in your AI projects?

---

I mainly focus on observability and testing for my own AI projects. I will put logger to help me track the system status. I like to categorise the logger into different level which are info log, warning log and error log. Info log will basically just return once a certain operation is done for audit purpose. Warning log will save issues that are not fatal, but would require actions soon. Lastly error log which will save all of the error that are fatal which will cause fatal or response error in the application.

As for testing, i mainly focus on unit testing and data validation test. For all data preparation functions, i will create unit tests for them and cover majority of the scenario, to make sure that in the future if anybody made changes to the code, the code will be still functioning properly. In any case the unit tests fail after a code changes, it means the user who has made the changes need to attend to it and fix it so that it will cover all cases again.

I implemented tests to validate the input data schema before training. This prevents training on corrupted or incorrectly formatted datasets.

